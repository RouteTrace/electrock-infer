import torch
from torch import nn
import time
from torch.utils.cpp_extension import load
from electrock_infer import _C


# -------------------------------------------------------------------
# æ­¥éª¤ 2: ç¼–å†™ä¸å†…æ ¸é€»è¾‘ä¸€è‡´çš„ PyTorch "Naive" ç‰ˆæœ¬
# -------------------------------------------------------------------

def torch_rms_norm(x: torch.Tensor, weight: torch.Tensor, eps: float):
    """
    ä¸å¸¦æ®‹å·®è¿æ¥çš„ RMSNorm çš„ PyTorch å®ç°ã€‚
    """
    # ä¸ºäº†ç²¾åº¦ç¨³å®šæ€§ï¼Œä½¿ç”¨ float32 è¿›è¡Œä¸­é—´è®¡ç®—
    variance = x.to(torch.float32).pow(2).mean(-1, keepdim=True)
    inv_rms = torch.rsqrt(variance + eps)
    
    # å°†ç»“æœè½¬æ¢å›åŸå§‹æ•°æ®ç±»å‹
    return (x * inv_rms).to(x.dtype) * weight

def torch_add_rms_norm(x: torch.Tensor, residual: torch.Tensor, weight: torch.Tensor, eps: float):
    """
    å¸¦æ®‹å·®è¿æ¥çš„ RMSNorm çš„ PyTorch å®ç°ã€‚
    æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°éœ€è¦æ¨¡æ‹Ÿå†…æ ¸çš„ in-place è¡Œä¸ºï¼š
    1. è®¡ç®— x = x + residual
    2. å¯¹æ–°çš„ x è¿›è¡Œ RMSNorm
    3. å°†åŸå§‹çš„ residual æ›´æ–°ä¸º x + residual çš„ç»“æœ
    """
    # 1. è®¡ç®— x + residual
    x_plus_res = x + residual
    
    # 2. å¯¹ç›¸åŠ åçš„ç»“æœè¿›è¡Œ RMSNorm
    variance = x_plus_res.to(torch.float32).pow(2).mean(-1, keepdim=True)
    inv_rms = torch.rsqrt(variance + eps)
    norm_x = (x_plus_res * inv_rms).to(x.dtype) * weight
    
    # 3. In-place æ›´æ–°åŸå§‹å¼ é‡
    x.copy_(norm_x)
    residual.copy_(x_plus_res)


# -------------------------------------------------------------------
# æ­¥éª¤ 1: åŠ¨æ€åŠ è½½ C++/HIP/CUDA æ‰©å±•
# -------------------------------------------------------------------
# PyTorch ä¼šè°ƒç”¨ç³»ç»Ÿçš„ C++ ç¼–è¯‘å™¨ (å¦‚ g++) å’Œè®¾å¤‡ç¼–è¯‘å™¨ (å¦‚ hipcc æˆ– nvcc)
# æ¥ç¼–è¯‘å’Œé“¾æ¥è¿™ä¸ªæºæ–‡ä»¶ã€‚
# verbose=True ä¼šåœ¨ç¼–è¯‘æ—¶æ‰“å°è¯¦ç»†çš„å‘½ä»¤å’Œè¾“å‡ºï¼Œéå¸¸æœ‰åŠ©äºæ’æŸ¥ç¼–è¯‘é”™è¯¯ã€‚
# try:
#     custom_kernels = load(
#         name="custom_rms_norm",
#         sources=["rms_norm_kernel.cpp"],
#         verbose=True
#     )
#     print("âœ… C++ extension loaded successfully.")
# except Exception as e:
#     print(f"âŒ Failed to load C++ extension: {e}")
#     exit()

# -------------------------------------------------------------------
# æ­¥éª¤ 3: è®¾ç½®æµ‹è¯•å‚æ•°å¹¶æ‰§è¡Œæµ‹è¯•
# -------------------------------------------------------------------

def run_test():
    # --- æµ‹è¯•å‚æ•° ---
    NUM_TOKENS = 60 * 1024
    HIDDEN_SIZE = 4096 # å†…æ ¸ä¸­æ–­è¨€äº†è¿™ä¸ªå€¼
    DTYPE = torch.half  # å¯ä»¥æ”¹ä¸º torch.bfloat16 æˆ– torch.float32
    EPSILON = 1e-5
    DEVICE = 'cuda'

    # --- æ€§èƒ½æµ‹è¯•è¿­ä»£æ¬¡æ•° ---
    warmup_iter = 10
    test_iter = 100

    if not torch.cuda.is_available():
        print("âŒ CUDA/ROCm device not found. Aborting.")
        return

    print("\n" + "="*50)
    print(f"Test Configuration:")
    print(f"  Device: {DEVICE}")
    print(f"  Num Tokens: {NUM_TOKENS}")
    print(f"  Hidden Size: {HIDDEN_SIZE}")
    print(f"  Data Type: {DTYPE}")
    print("="*50 + "\n")

    # --- æµ‹è¯• `rms_norm` (ä¸å¸¦æ®‹å·®) ---
    print("--- ğŸ”¬ Testing `rms_norm` (without residual) ---")
    
    # åˆ›å»ºè¾“å…¥æ•°æ®
    input_tensor = torch.randn(NUM_TOKENS, HIDDEN_SIZE, device=DEVICE, dtype=DTYPE)
    weight_tensor = torch.randn(HIDDEN_SIZE, device=DEVICE, dtype=DTYPE)
    
    # ä¸ºè‡ªå®šä¹‰å†…æ ¸å’Œtorchç‰ˆæœ¬åˆ›å»ºå‰¯æœ¬ï¼Œä»¥ä¿è¯å…¬å¹³æ¯”è¾ƒ
    input_custom = input_tensor.clone()
    input_torch = input_tensor.clone()
    
    # è¿è¡Œ torch naive ç‰ˆæœ¬å¹¶éªŒè¯
    output_torch = torch_rms_norm(input_torch, weight_tensor, EPSILON)
    torch.cuda.synchronize()
    # è¿è¡Œè‡ªå®šä¹‰å†…æ ¸ç‰ˆæœ¬
    _C.rms_norm(input_custom, EPSILON, weight_tensor)
    torch.cuda.synchronize()
    # éªŒè¯æ­£ç¡®æ€§
    # atol (absolute tolerance) è®¾ä¸º 1e-2 æ˜¯å› ä¸º half/bfloat16 ç²¾åº¦è¾ƒä½
    is_correct = torch.allclose(input_custom, output_torch, atol=1e-2)
    print(f"Correctness Check: {'PASS âœ…' if is_correct else 'FAIL âŒ'}")
    print("Max difference:", (input_custom - output_torch).abs().max())

    # æ€§èƒ½è¯„æµ‹
    # Warm-up
    for _ in range(warmup_iter):
        _C.rms_norm(input_custom, EPSILON, weight_tensor)
        _ = torch_rms_norm(input_torch, weight_tensor, EPSILON)
    torch.cuda.synchronize()

    # Custom Kernel
    start_time = time.perf_counter()
    for _ in range(test_iter):
        _C.rms_norm(input_custom, EPSILON, weight_tensor)
    torch.cuda.synchronize()
    custom_time = (time.perf_counter() - start_time) / test_iter * 1000 # ms
    print(f"Custom Kernel Time: {custom_time:.4f} ms")

    # PyTorch Naive
    start_time = time.perf_counter()
    for _ in range(test_iter):
        _ = torch_rms_norm(input_torch, weight_tensor, EPSILON)
    torch.cuda.synchronize()
    torch_time = (time.perf_counter() - start_time) / test_iter * 1000 # ms
    print(f"PyTorch Naive Time: {torch_time:.4f} ms")
    print(f"ğŸš€ Speedup: {torch_time / custom_time:.2f}x")

    print("\n" + "-"*50 + "\n")

    # --- æµ‹è¯• `add_rms_norm` (å¸¦æ®‹å·®) ---
    print("--- ğŸ”¬ Testing `add_rms_norm` (with residual) ---")
    
    # åˆ›å»ºè¾“å…¥æ•°æ®
    input_tensor = torch.randn(NUM_TOKENS, HIDDEN_SIZE, device=DEVICE, dtype=DTYPE)
    residual_tensor = torch.randn(NUM_TOKENS, HIDDEN_SIZE, device=DEVICE, dtype=DTYPE)
    weight_tensor = torch.randn(HIDDEN_SIZE, device=DEVICE, dtype=DTYPE)

    # åˆ›å»ºå‰¯æœ¬
    input_custom = input_tensor.clone()
    residual_custom = residual_tensor.clone()
    input_torch = input_tensor.clone()
    residual_torch = residual_tensor.clone()

    # è¿è¡Œ torch naive ç‰ˆæœ¬
    torch_add_rms_norm(input_torch, residual_torch, weight_tensor, EPSILON)
    torch.cuda.synchronize()
    # è¿è¡Œè‡ªå®šä¹‰å†…æ ¸ç‰ˆæœ¬
    _C.add_rms_norm(input_custom, residual_custom, EPSILON, weight_tensor)
    torch.cuda.synchronize()
    # éªŒè¯æ­£ç¡®æ€§
    # éªŒè¯ä¸¤ä¸ªè¾“å‡ºï¼šinput å’Œ residual
    is_correct_input = torch.allclose(input_custom, input_torch, atol=1e-2)
    is_correct_residual = torch.allclose(residual_custom, residual_torch, atol=1e-2)
    print(f"Correctness Check (input): {'PASS âœ…' if is_correct_input else 'FAIL âŒ'}")
    print(f"Correctness Check (residual): {'PASS âœ…' if is_correct_residual else 'FAIL âŒ'}")

    print("Max input difference:", (input_custom - input_torch).abs().max())
    print("Max residual difference:", (residual_custom - residual_torch).abs().max())
    # æ€§èƒ½è¯„æµ‹
    # Warm-up
    for _ in range(warmup_iter):
       _C.add_rms_norm(input_custom, residual_custom, EPSILON, weight_tensor)
       torch_add_rms_norm(input_torch, residual_torch, weight_tensor, EPSILON)
    torch.cuda.synchronize()

    # Custom Kernel
    start_time = time.perf_counter()
    for _ in range(test_iter):
        _C.add_rms_norm(input_custom, residual_custom, EPSILON, weight_tensor)
    torch.cuda.synchronize()
    custom_time = (time.perf_counter() - start_time) / test_iter * 1000 # ms
    print(f"Custom Kernel Time: {custom_time:.4f} ms")

    # PyTorch Naive
    start_time = time.perf_counter()
    for _ in range(test_iter):
        torch_add_rms_norm(input_torch, residual_torch, weight_tensor, EPSILON)
    torch.cuda.synchronize()
    torch_time = (time.perf_counter() - start_time) / test_iter * 1000 # ms
    print(f"PyTorch Naive Time: {torch_time:.4f} ms")
    print(f"ğŸš€ Speedup: {torch_time / custom_time:.2f}x")


if __name__ == "__main__":
    run_test()